{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4bfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Simulated example data\n",
    "durations = np.random.exponential(scale=180, size=100)  # days to upgrade or censor\n",
    "event_observed = np.random.binomial(1, 0.7, size=100)  # 1 if upgraded, 0 if censored\n",
    "\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(durations, event_observed, label=\"Green Tier Upgrade\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "kmf.plot_survival_function()\n",
    "plt.title(\"Kaplan–Meier Curve: Time to Upgrade from Green Tier\")\n",
    "plt.xlabel(\"Days since entry to Green Tier\")\n",
    "plt.ylabel(\"Proportion still in Green Tier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# Simulated data setup\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create synthetic durations (days until upgrade or censor)\n",
    "# and events (1=upgraded, 0=censored) for 3 frequency groups\n",
    "\n",
    "n = 100  # number of customers per group\n",
    "\n",
    "# Low frequency: slower upgrades (longer times)\n",
    "durations_low = np.random.exponential(scale=250, size=n)\n",
    "events_low = np.random.binomial(1, 0.6, size=n)  # 60% upgraded\n",
    "\n",
    "# Medium frequency: medium speed upgrades\n",
    "durations_med = np.random.exponential(scale=180, size=n)\n",
    "events_med = np.random.binomial(1, 0.7, size=n)\n",
    "\n",
    "# High frequency: faster upgrades\n",
    "durations_high = np.random.exponential(scale=120, size=n)\n",
    "events_high = np.random.binomial(1, 0.8, size=n)\n",
    "\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot Low frequency group\n",
    "kmf.fit(durations_low, event_observed=events_low, label=\"Low Visit Frequency\")\n",
    "kmf.plot_survival_function()\n",
    "\n",
    "# Plot Medium frequency group\n",
    "kmf.fit(durations_med, event_observed=events_med, label=\"Medium Visit Frequency\")\n",
    "kmf.plot_survival_function()\n",
    "\n",
    "# Plot High frequency group\n",
    "kmf.fit(durations_high, event_observed=events_high, label=\"High Visit Frequency\")\n",
    "kmf.plot_survival_function()\n",
    "\n",
    "plt.title(\"Kaplan–Meier Curves by Visit Frequency Group\")\n",
    "plt.xlabel(\"Days Since Entering Green Tier\")\n",
    "plt.ylabel(\"Proportion Still in Green Tier (Not Upgraded)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Statistical test example: Low vs High frequency groups\n",
    "results = logrank_test(durations_low, durations_high,\n",
    "                       event_observed_A=events_low,\n",
    "                       event_observed_B=events_high)\n",
    "print(f\"Log-rank test p-value (Low vs High frequency): {results.p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['Visit Frequency', 'Average Spend', 'App Usage', 'Reminder Sent']\n",
    "hazard_ratios = [1.5, 1.2, 1.8, 2.0]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "bars = plt.bar(factors, hazard_ratios, color='skyblue')\n",
    "plt.axhline(1, color='red', linestyle='--')\n",
    "plt.title(\"Cox Model: Impact on Upgrade Speed (Hazard Ratios)\")\n",
    "plt.ylabel(\"Hazard Ratio (>1 = faster upgrade)\")\n",
    "plt.ylim(0, 2.5)\n",
    "for bar, hr in zip(bars, hazard_ratios):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() - 0.15, f\"{hr:.2f}\", ha='center', color='black', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "matrix = pd.DataFrame({\n",
    "    'Green': [0.7, 0.1, 0.0],\n",
    "    'Silver': [0.25, 0.8, 0.05],\n",
    "    'Gold': [0.0, 0.08, 0.9],\n",
    "    'Exit': [0.05, 0.02, 0.05]\n",
    "}, index=['Green', 'Silver', 'Gold'])\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(matrix, annot=True, cmap='Blues', cbar=False, fmt=\".2f\")\n",
    "plt.title(\"Markov Chain: Monthly Tier Transition Probabilities\")\n",
    "plt.ylabel(\"Current Tier\")\n",
    "plt.xlabel(\"Next Tier\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b03bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated visit frequencies (visits per month)\n",
    "before = np.random.poisson(lam=2.5, size=100)\n",
    "after = before + np.random.choice([0,1], size=100, p=[0.7,0.3])  # some increase\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.boxplot([before, after], labels=['Before Reminder', 'After Reminder'])\n",
    "plt.title(\"Visit Frequency Before vs After Reminder\")\n",
    "plt.ylabel(\"Average Monthly Visits\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "num_customers = 10\n",
    "start_date = pd.Timestamp('2024-01-01')\n",
    "end_date = pd.Timestamp('2025-07-31')\n",
    "date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "# Generate random transaction dates for each customer (biweekly approx)\n",
    "def random_dates(num, start, end):\n",
    "    return pd.to_datetime(np.random.choice(pd.date_range(start, end), num, replace=False)).sort_values()\n",
    "\n",
    "data = []\n",
    "\n",
    "for cust_id in range(1, num_customers + 1):\n",
    "    num_tx = np.random.randint(20, 40)  # transactions per customer\n",
    "    tx_dates = random_dates(num_tx, start_date, end_date)\n",
    "    cumulative_points = 0\n",
    "    group_num = 0\n",
    "    \n",
    "    for i, tx_date in enumerate(tx_dates):\n",
    "        # Randomly assign transaction category\n",
    "        if np.random.rand() < 0.1:\n",
    "            # 10% chance of upgrade/downgrade\n",
    "            category = np.random.choice(['Upgrade', 'Downgrade'])\n",
    "            point_reset_flag = 1\n",
    "            # Points at upgrade equal cumulative_points\n",
    "            issued_points = cumulative_points\n",
    "            # Reset cumulative points after upgrade/downgrade\n",
    "            cumulative_points = 0\n",
    "            group_num += 1\n",
    "        else:\n",
    "            category = 'Normal'\n",
    "            point_reset_flag = 0\n",
    "            issued_points = np.random.randint(10, 100)\n",
    "            cumulative_points += issued_points\n",
    "        \n",
    "        data.append({\n",
    "            'LOYALTY_CUSTOMER_REF': f'CUST{cust_id:03d}',\n",
    "            'LOYALTY_TRX_DATE': tx_date,\n",
    "            'LOYALTY_TRX_CATEGORY_REF': category,\n",
    "            'ISSUED_LOYALTY_POINTS': issued_points,\n",
    "            'POINT_RESET_FLAG': point_reset_flag,\n",
    "            'GROUP': group_num\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate cumulative points per customer and group (mimic SQL logic)\n",
    "df = df.sort_values(['LOYALTY_CUSTOMER_REF', 'LOYALTY_TRX_DATE'])\n",
    "df['CUMULATIVE_POINTS'] = df.groupby(['LOYALTY_CUSTOMER_REF', 'GROUP'])['ISSUED_LOYALTY_POINTS'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# === Data Generation ===\n",
    "num_customers = 10\n",
    "start_date = pd.Timestamp('2024-01-01')\n",
    "end_date = pd.Timestamp('2025-07-31')\n",
    "\n",
    "def random_dates(num, start, end):\n",
    "    return pd.to_datetime(np.random.choice(pd.date_range(start, end), num, replace=False)).sort_values()\n",
    "\n",
    "data = []\n",
    "\n",
    "for cust_id in range(1, num_customers + 1):\n",
    "    num_tx = np.random.randint(20, 40)  # transactions per customer\n",
    "    tx_dates = random_dates(num_tx, start_date, end_date)\n",
    "    cumulative_points = 0\n",
    "    group_num = 0\n",
    "    \n",
    "    for tx_date in tx_dates:\n",
    "        if np.random.rand() < 0.1:\n",
    "            category = np.random.choice(['Upgrade', 'Downgrade'])\n",
    "            point_reset_flag = 1\n",
    "            issued_points = cumulative_points\n",
    "            cumulative_points = 0\n",
    "            group_num += 1\n",
    "        else:\n",
    "            category = 'Normal'\n",
    "            point_reset_flag = 0\n",
    "            issued_points = np.random.randint(10, 100)\n",
    "            cumulative_points += issued_points\n",
    "        \n",
    "        data.append({\n",
    "            'LOYALTY_CUSTOMER_REF': f'CUST{cust_id:03d}',\n",
    "            'LOYALTY_TRX_DATE': tx_date,\n",
    "            'LOYALTY_TRX_CATEGORY_REF': category,\n",
    "            'ISSUED_LOYALTY_POINTS': issued_points,\n",
    "            'POINT_RESET_FLAG': point_reset_flag,\n",
    "            'GROUP': group_num\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sort_values(['LOYALTY_CUSTOMER_REF', 'LOYALTY_TRX_DATE'])\n",
    "df['CUMULATIVE_POINTS'] = df.groupby(['LOYALTY_CUSTOMER_REF', 'GROUP'])['ISSUED_LOYALTY_POINTS'].cumsum()\n",
    "\n",
    "# === Analysis Functions with plots ===\n",
    "\n",
    "def time_to_threshold(df, threshold=1000):\n",
    "    threshold_dates = (\n",
    "        df[df['CUMULATIVE_POINTS'] >= threshold]\n",
    "        .groupby('LOYALTY_CUSTOMER_REF')['LOYALTY_TRX_DATE']\n",
    "        .min()\n",
    "        .reset_index()\n",
    "        .rename(columns={'LOYALTY_TRX_DATE': 'DATE_THRESHOLD_REACHED'})\n",
    "    )\n",
    "    \n",
    "    first_dates = (\n",
    "        df.groupby('LOYALTY_CUSTOMER_REF')['LOYALTY_TRX_DATE']\n",
    "        .min()\n",
    "        .reset_index()\n",
    "        .rename(columns={'LOYALTY_TRX_DATE': 'FIRST_TX_DATE'})\n",
    "    )\n",
    "    \n",
    "    result = pd.merge(first_dates, threshold_dates, on='LOYALTY_CUSTOMER_REF', how='left')\n",
    "    result['DAYS_TO_THRESHOLD'] = (result['DATE_THRESHOLD_REACHED'] - result['FIRST_TX_DATE']).dt.days\n",
    "    return result\n",
    "\n",
    "def plot_time_to_threshold(df_res):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df_res, x='LOYALTY_CUSTOMER_REF', y='DAYS_TO_THRESHOLD', palette='viridis')\n",
    "    plt.title('Days to Reach 1000 Points Threshold')\n",
    "    plt.ylabel('Days')\n",
    "    plt.xlabel('Customer')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visit_based_pace(df):\n",
    "    visits = (\n",
    "        df.groupby('LOYALTY_CUSTOMER_REF')\n",
    "        .agg(TOTAL_POINTS=('ISSUED_LOYALTY_POINTS', 'sum'), \n",
    "             TOTAL_VISITS=('LOYALTY_TRX_DATE', 'count'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    visits['POINTS_PER_VISIT'] = visits['TOTAL_POINTS'] / visits['TOTAL_VISITS']\n",
    "    return visits\n",
    "\n",
    "def plot_visit_based_pace(df_visits):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df_visits, x='LOYALTY_CUSTOMER_REF', y='POINTS_PER_VISIT', palette='coolwarm')\n",
    "    plt.title('Average Points per Visit by Customer')\n",
    "    plt.ylabel('Points per Visit')\n",
    "    plt.xlabel('Customer')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def max_span_since_last_upgrade(df):\n",
    "    upgrades = df[df['POINT_RESET_FLAG'] == 1]\n",
    "    \n",
    "    spans = []\n",
    "    for cust, group_df in df.groupby('LOYALTY_CUSTOMER_REF'):\n",
    "        upgrade_dates = upgrades[upgrades['LOYALTY_CUSTOMER_REF'] == cust]['LOYALTY_TRX_DATE']\n",
    "        last_upgrade = upgrade_dates.max() if not upgrade_dates.empty else None\n",
    "        last_tx = group_df['LOYALTY_TRX_DATE'].max()\n",
    "        if last_upgrade is None:\n",
    "            span = (last_tx - group_df['LOYALTY_TRX_DATE'].min()).days\n",
    "        else:\n",
    "            span = (last_tx - last_upgrade).days\n",
    "        spans.append({'LOYALTY_CUSTOMER_REF': cust, 'DAYS_SINCE_LAST_UPGRADE': span})\n",
    "    return pd.DataFrame(spans)\n",
    "\n",
    "def plot_max_span(df_spans):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df_spans, x='LOYALTY_CUSTOMER_REF', y='DAYS_SINCE_LAST_UPGRADE', palette='magma')\n",
    "    plt.title('Days Since Last Upgrade per Customer')\n",
    "    plt.ylabel('Days Since Last Upgrade')\n",
    "    plt.xlabel('Customer')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def flag_zero_upgrades(df):\n",
    "    upgrades_count = df[df['POINT_RESET_FLAG'] == 1].groupby('LOYALTY_CUSTOMER_REF').size().reset_index(name='UPGRADE_COUNT')\n",
    "    all_customers = df['LOYALTY_CUSTOMER_REF'].unique()\n",
    "    upgrades_flag = pd.DataFrame({'LOYALTY_CUSTOMER_REF': all_customers})\n",
    "    upgrades_flag = upgrades_flag.merge(upgrades_count, on='LOYALTY_CUSTOMER_REF', how='left').fillna(0)\n",
    "    upgrades_flag['NO_UPGRADE_FLAG'] = (upgrades_flag['UPGRADE_COUNT'] == 0).astype(int)\n",
    "    return upgrades_flag[['LOYALTY_CUSTOMER_REF', 'NO_UPGRADE_FLAG']]\n",
    "\n",
    "def plot_zero_upgrade_flag(df_flag):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df_flag, x='LOYALTY_CUSTOMER_REF', y='NO_UPGRADE_FLAG', palette='Set2')\n",
    "    plt.title('Customers with Zero Upgrades Flag (1 = No Upgrades)')\n",
    "    plt.ylabel('No Upgrade Flag')\n",
    "    plt.xlabel('Customer')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def cohort_analysis(df):\n",
    "    df['COHORT_MONTH'] = df.groupby('LOYALTY_CUSTOMER_REF')['LOYALTY_TRX_DATE'].transform('min').dt.to_period('M')\n",
    "    df['TX_MONTH'] = df['LOYALTY_TRX_DATE'].dt.to_period('M')\n",
    "    cohort_data = df.groupby(['COHORT_MONTH', 'TX_MONTH']).size().unstack(fill_value=0)\n",
    "    return cohort_data\n",
    "\n",
    "def plot_cohort_analysis(cohort_df):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(cohort_df, annot=True, fmt='d', cmap='YlGnBu')\n",
    "    plt.title('Cohort Analysis: Transaction Counts by Cohort Month and Transaction Month')\n",
    "    plt.ylabel('Cohort Month')\n",
    "    plt.xlabel('Transaction Month')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Run and plot ===\n",
    "\n",
    "time_thresh_res = time_to_threshold(df)\n",
    "plot_time_to_threshold(time_thresh_res)\n",
    "\n",
    "visit_pace_res = visit_based_pace(df)\n",
    "plot_visit_based_pace(visit_pace_res)\n",
    "\n",
    "max_span_res = max_span_since_last_upgrade(df)\n",
    "plot_max_span(max_span_res)\n",
    "\n",
    "zero_upgrade_flag_res = flag_zero_upgrades(df)\n",
    "plot_zero_upgrade_flag(zero_upgrade_flag_res)\n",
    "\n",
    "cohort_res = cohort_analysis(df)\n",
    "plot_cohort_analysis(cohort_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time differences and points differences per customer transaction\n",
    "df = df.sort_values(['LOYALTY_CUSTOMER_REF', 'LOYALTY_TRX_DATE'])\n",
    "\n",
    "df['PREV_DATE'] = df.groupby('LOYALTY_CUSTOMER_REF')['LOYALTY_TRX_DATE'].shift(1)\n",
    "df['PREV_POINTS'] = df.groupby('LOYALTY_CUSTOMER_REF')['CUMULATIVE_POINTS'].shift(1)\n",
    "\n",
    "df['DAYS_DIFF'] = (df['LOYALTY_TRX_DATE'] - df['PREV_DATE']).dt.days\n",
    "df['POINTS_DIFF'] = df['CUMULATIVE_POINTS'] - df['PREV_POINTS']\n",
    "\n",
    "df['VELOCITY'] = df['POINTS_DIFF'] / df['DAYS_DIFF']\n",
    "df.loc[df['DAYS_DIFF'] == 0, 'VELOCITY'] = np.nan  # avoid divide by zero\n",
    "\n",
    "# Plot velocity vectors (points/day) over time per customer\n",
    "plt.figure(figsize=(14, 7))\n",
    "for cust in df['LOYALTY_CUSTOMER_REF'].unique():\n",
    "    cust_data = df[df['LOYALTY_CUSTOMER_REF'] == cust]\n",
    "    plt.plot(cust_data['LOYALTY_TRX_DATE'], cust_data['VELOCITY'], marker='o', label=cust)\n",
    "\n",
    "plt.title('Velocity of Points Accumulation (Points/Day) Over Time by Customer')\n",
    "plt.xlabel('Transaction Date')\n",
    "plt.ylabel('Velocity (Points/Day)')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Prepare survival data\n",
    "df_sorted = df.sort_values(['LOYALTY_CUSTOMER_REF', 'LOYALTY_TRX_DATE'])\n",
    "first_tx = df_sorted.groupby('LOYALTY_CUSTOMER_REF')['LOYALTY_TRX_DATE'].min().reset_index()\n",
    "upgrade_tx = df_sorted[df_sorted['POINT_RESET_FLAG'] == 1].groupby('LOYALTY_CUSTOMER_REF')['LOYALTY_TRX_DATE'].min().reset_index()\n",
    "\n",
    "surv_data = first_tx.merge(upgrade_tx, on='LOYALTY_CUSTOMER_REF', how='left', suffixes=('_first', '_upgrade'))\n",
    "surv_data['EVENT_OCCURRED'] = surv_data['LOYALTY_TRX_DATE_upgrade'].notna().astype(int)\n",
    "\n",
    "# Calculate duration (days) between first transaction and upgrade or censor date (end of data)\n",
    "end_date = df['LOYALTY_TRX_DATE'].max()\n",
    "surv_data['DURATION'] = (surv_data['LOYALTY_TRX_DATE_upgrade'].fillna(end_date) - surv_data['LOYALTY_TRX_DATE_first']).dt.days\n",
    "\n",
    "# Fit Kaplan-Meier\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(durations=surv_data['DURATION'], event_observed=surv_data['EVENT_OCCURRED'])\n",
    "\n",
    "# Plot survival curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "kmf.plot_survival_function()\n",
    "plt.title('Kaplan-Meier Survival Curve: Time to Upgrade Event')\n",
    "plt.xlabel('Days Since First Transaction')\n",
    "plt.ylabel('Probability of No Upgrade Yet')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
